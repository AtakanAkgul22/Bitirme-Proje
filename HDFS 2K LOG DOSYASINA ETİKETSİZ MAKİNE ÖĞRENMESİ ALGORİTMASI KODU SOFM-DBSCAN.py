from minisom import MiniSom
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import DBSCAN
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Pandas ile veriyi okuyoruz.
veri = pd.read_csv("C:/Users/atkn_/Desktop/AAA/features_hdfs_labeled.csv")

#  Ã–zellik (X) ve etiket (y) ayÄ±rma iÅŸlemi.
# 'BlockId' ve 'label' dÄ±ÅŸÄ±nda kalan sÃ¼tunlar Ã¶zellik vektÃ¶rÃ¼nÃ¼ oluÅŸturur.
# Etiketler: Normal â†’ 0, Anomaly â†’ 1 olarak sayÄ±sallaÅŸtÄ±rÄ±lÄ±r.
ozellikler = veri.drop(columns=["label", "BlockId"], errors="ignore")
gercek_etiketler = veri["label"].map({"Normal": 0, "Anomaly": 1})

# Ã–zellikleri normalize ediyoruz. (standardizasyon)
# Bu iÅŸlem, SOFM gibi mesafe temelli algoritmalarda tÃ¼m deÄŸiÅŸkenlerin eÅŸit Ã¶lÃ§eÄŸe getirilmesini saÄŸlar.
olceklendirici = StandardScaler()
ozellikler_olcekli = olceklendirici.fit_transform(ozellikler)

# SOFM (Self-Organizing Feature Map) modeli oluÅŸturuyoruz.
# MiniSom, Ã¶rÃ¼ntÃ¼lerin iki boyutlu haritada gruplandÄ±rÄ±lmasÄ±nÄ± saÄŸlar.
# x=10, y=10: Harita boyutu (100 nÃ¶ron), input_len: GiriÅŸ vektÃ¶rÃ¼nÃ¼n boyutu.
som = MiniSom(
    x=10,
    y=10,
    input_len=ozellikler_olcekli.shape[1],
    sigma=1.0,
    learning_rate=0.5,
    random_seed=42
)
som.random_weights_init(ozellikler_olcekli)  # BaÅŸlangÄ±Ã§ aÄŸÄ±rlÄ±klarÄ± rastgele atanÄ±r
som.train_random(ozellikler_olcekli, 1000)   # 1000 iterasyonluk rastgele eÄŸitim yapÄ±lÄ±r

# SOFM Ã§Ä±ktÄ±larÄ±nÄ± elde ediyoruz.
# Her giriÅŸ vektÃ¶rÃ¼ iÃ§in en yakÄ±n nÃ¶ron (BMU - Best Matching Unit) koordinatÄ± alÄ±nÄ±r.
# Ã–rneÄŸin (4, 7) gibi bir 2D grid koordinatÄ±.
bmu_koordinatlari = np.array([som.winner(x) for x in ozellikler_olcekli])

# KoordinatlarÄ± normalize et: Harita boyutu 10 olduÄŸundan (0,10) aralÄ±ÄŸÄ±nÄ± (0,1)'e Ã§evir.
# Bu normalizasyon DBSCANâ€™in eps parametresiyle daha stabil Ã§alÄ±ÅŸmasÄ±nÄ± saÄŸlar.
bmu_koordinatlari_normalize = bmu_koordinatlari / 10.0

# DBSCAN kÃ¼meleme algoritmasÄ±nÄ± uyguluyoruz.
# DBSCAN, yoÄŸunluk tabanlÄ± bir kÃ¼meleme algoritmasÄ±dÄ±r ve -1 etiketini outlier (anomaly) olarak verir.
# eps: KomÅŸuluk yarÄ±Ã§apÄ±, min_samples: Bir noktayÄ± Ã§ekirdek nokta saymak iÃ§in minimum komÅŸu sayÄ±sÄ±.
dbscan_modeli = DBSCAN(eps=0.2, min_samples=5)
dbscan_etiketleri = dbscan_modeli.fit_predict(bmu_koordinatlari_normalize)

# DBSCAN Ã§Ä±ktÄ±sÄ±nda -1 olarak iÅŸaretlenen Ã¶rnekler anomali kabul edilir
# Bu nedenle tahminler 0 (normal) ve 1 (anomaly) olarak dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r
sofm_dbscan_tahmin = (dbscan_etiketleri == -1).astype(int)

# Performans deÄŸerlendirmesi kÄ±smÄ±.
# GerÃ§ek etiketlerle modelin tahmin ettiÄŸi etiketler karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r.
# Precision, recall, f1-score gibi metrikler yazdÄ±rÄ±lÄ±r.
print("\nğŸ”¹ SOFM-DBSCAN SonuÃ§larÄ±")
print(classification_report(
    gercek_etiketler,
    sofm_dbscan_tahmin,
    target_names=["Normal", "Anomali"],
    zero_division=0
))

