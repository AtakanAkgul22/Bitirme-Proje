import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score, classification_report
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from xgboost import XGBClassifier


# Bu veri kÃ¼mesinde her satÄ±r bir BlockId'ye karÅŸÄ±lÄ±k gelen EventId sayÄ±mlarÄ±nÄ± ve etiketini iÃ§erir.
veri = pd.read_csv("C:/Users/atkn_/Desktop/AAA/features_hdfs_labeled.csv") # Bu kÄ±sÄ±m etiketli Ã¶zellik vektÃ¶rlerini CSV dosyasÄ±ndan okur

# Ã–zellikler (X) ve etiketler (y) olarak veriyi ayÄ±rÄ±yoruz.
# Etiket: "label" sÃ¼tunu â€” Normal (0) veya Anomali (1)
# Ã–zellikler: "BlockId" ve "label" dÄ±ÅŸÄ±ndaki tÃ¼m sÃ¼tunlardÄ±r.
ozellikler = veri.drop(columns=["label", "BlockId"], errors="ignore")  # features = X
etiketler = veri["label"]  # target = y

# EÄŸer etiketler metin (string) formatÄ±ndaysa sayÄ±sal formata dÃ¶nÃ¼ÅŸtÃ¼rmemiz gerekiyor o yÃ¼zden koda bu kÄ±smÄ± ekliyoruz.
etiketler = etiketler.map({"Normal": 0, "Anomaly": 1})

# EÄŸitim ve test verisini ayÄ±rÄ±yoruz.
# %80 eÄŸitim, %20 test oranÄ±yla rastgele ancak sÄ±nÄ±f oranlarÄ±nÄ± koruyacak ÅŸekilde bÃ¶lÃ¼yoruz.
ozellikler_egitim, ozellikler_test, etiketler_egitim, etiketler_test = train_test_split(
    ozellikler, etiketler, test_size=0.2, random_state=42, stratify=etiketler
)

# KullanÄ±lacak sÄ±nÄ±flandÄ±rma modellerini tanÄ±mlÄ±yoruz.
# Logistic Regression, Random Forest, SVM ve XGBoost modelleri karÅŸÄ±laÅŸtÄ±rÄ±lacaktÄ±r
modeller = {
    "Lojistik Regresyon": LogisticRegression(max_iter=500, class_weight='balanced'),
    "Rasgele Orman": RandomForestClassifier(class_weight='balanced'),
    "Destek VektÃ¶r Makinesi (SVM)": SVC(class_weight='balanced'),
    "XGBoost": XGBClassifier(eval_metric='logloss')  # logloss: binary sÄ±nÄ±flama iÃ§in uygun deÄŸerlendirme metriÄŸi
}

# Her bir modeli sÄ±rayla eÄŸitiyoruz ve test seti Ã¼zerinde deÄŸerlendiriyoruz.
for model_adi, model in modeller.items():
    model.fit(ozellikler_egitim, etiketler_egitim)  # Modeli eÄŸitim verisiyle eÄŸitiyoruz.
    tahminler = model.predict(ozellikler_test)      # Test verisi Ã¼zerinde tahmin yapÄ±yoruz.
    
    # DoÄŸruluk (accuracy) ve F1 skoru hesaplÄ±yoruz.
    dogruluk = accuracy_score(etiketler_test, tahminler)
    f1 = f1_score(etiketler_test, tahminler, pos_label=1, zero_division=0)
    
    # SonuÃ§larÄ± ekrana yazdÄ±rÄ±yoruz.
    print(f"\nğŸ”¹ {model_adi}")
    print(f"   âœ… DoÄŸruluk (Accuracy): {dogruluk:.4f} | F1 Skoru: {f1:.4f}")
    
    # SÄ±nÄ±f bazlÄ± precision, recall ve F1 skoru raporu
    print(classification_report(
        etiketler_test,
        tahminler,
        target_names=["Normal", "Anomali"],
        zero_division=0
    ))
