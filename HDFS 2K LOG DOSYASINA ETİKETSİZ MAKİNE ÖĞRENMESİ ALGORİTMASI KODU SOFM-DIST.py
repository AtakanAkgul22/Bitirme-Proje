from minisom import MiniSom
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Pandas ile veriyi okuyoruz.
veri = pd.read_csv("C:/Users/atkn_/Desktop/AAA/features_hdfs_labeled.csv")

# Ã–zellikleri ve etiketleri ayÄ±rÄ±yoruz.
# 'label' ve 'BlockId' sÃ¼tunlarÄ± analiz iÃ§in gerekli deÄŸildir. Model sadece sayÄ±sal Ã¶zellik vektÃ¶rleri ile Ã§alÄ±ÅŸÄ±r.
# Bu nedenle sadece EventID frekanslarÄ±nÄ±n bulunduÄŸu sÃ¼tunlar alÄ±yoruz..
ozellikler = veri.drop(columns=["label", "BlockId"], errors="ignore")

# Etiket bilgisi (Normal, Anomaly) sayÄ±sal forma Ã§evririyoruz.
# Bu iÅŸlem deÄŸerlendirme metriklerinde kullanÄ±lacak olan gerÃ§ek etiket kÃ¼mesini oluÅŸturur.
gercek_etiketler = veri["label"].map({"Normal": 0, "Anomaly": 1})

# Ã–zellikleri standardize ediyoruz. Ã‡Ã¼nkÃ¼ SOFM gibi mesafe tabanlÄ± algoritmalarda her Ã¶zelliÄŸin aynÄ± skala aralÄ±ÄŸÄ±nda olmasÄ± Ã¶nemlidir.
# Aksi takdirde bÃ¼yÃ¼k deÄŸere sahip deÄŸiÅŸkenler mesafeye daha fazla etki eder.
olceklendirici = StandardScaler()
ozellikler_olcekli = olceklendirici.fit_transform(ozellikler)

# MiniSom (SOFM) modelini tanÄ±mlÄ±yoruz.
# x=10, y=10: SOM haritasÄ±nÄ±n boyutlarÄ±dÄ±r. Toplamda 100 nÃ¶ronluk bir grid.
# input_len: GiriÅŸ vektÃ¶rÃ¼nÃ¼n boyutu, yani kaÃ§ adet EventID Ã¶zelliÄŸi varsa o kadar.
# sigma: KomÅŸuluk yarÄ±Ã§apÄ± (nÃ¶ronlara yayÄ±lma etkisi); yÃ¼ksek sigma daha yaygÄ±n bir etki yaratÄ±r.
# learning_rate: Ã–ÄŸrenme oranÄ±; bÃ¼yÃ¼k deÄŸerler hÄ±zlÄ± Ã¶ÄŸrenmeye, kÃ¼Ã§Ã¼k deÄŸerler daha hassas gÃ¼ncellemeye neden olur.
# random_seed: RastgeleliÄŸe baÄŸlÄ± davranÄ±ÅŸÄ± tekrarlanabilir hale getirmek iÃ§in sabit tutulur.
som = MiniSom(
    x=10, y=10,
    input_len=ozellikler_olcekli.shape[1],
    sigma=1.0,
    learning_rate=0.5,
    random_seed=42
)

# SOFM aÄŸÄ±ndaki her nÃ¶ronun aÄŸÄ±rlÄ±klarÄ±nÄ± rastgele baÅŸlatÄ±yoruz.
som.random_weights_init(ozellikler_olcekli)

# SOFM eÄŸitim sÃ¼reci baÅŸlatÄ±yoruz.
# 1000 iterasyon boyunca her seferinde rastgele bir Ã¶rnek seÃ§ilerek aÄŸ eÄŸitilecek.
# Bu sÃ¼reÃ§te hem en yakÄ±n nÃ¶ronun aÄŸÄ±rlÄ±klarÄ± hem de komÅŸularÄ±nÄ±n aÄŸÄ±rlÄ±klarÄ± gÃ¼ncellenecek.
som.train_random(ozellikler_olcekli, 1000)

# Her veri Ã¶rneÄŸi iÃ§in En Ä°yi EÅŸleÅŸen NÃ¶ron'a (BMU) olan Ã¶klidyen mesafeyi hesaplanacak.
# Her veri noktasÄ± iÃ§in, kendisine en yakÄ±n olan nÃ¶ronun (BMU) aÄŸÄ±rlÄ±k vektÃ¶rÃ¼ bulunacak.
# Bu BMU'nun aÄŸÄ±rlÄ±ÄŸÄ± ile veri Ã¶rneÄŸi arasÄ±ndaki mesafe hesaplanÄ±r.
# Bu mesafe ne kadar bÃ¼yÃ¼kse, o Ã¶rnek SOM haritasÄ±na o kadar "yabancÄ±dÄ±r" yani potansiyel anomali olabilir.
bmu_uzakliklari = np.array([
    np.linalg.norm(
        veri_noktasi - som.get_weights()[som.winner(veri_noktasi)[0]][som.winner(veri_noktasi)[1]]
    )
    for veri_noktasi in ozellikler_olcekli
])

# Anomali eÅŸik deÄŸeri (threshold) belirlenecek.
# UzaklÄ±klarÄ±n %95'inden bÃ¼yÃ¼k olanlar anomali kabul edilecek Ã§Ã¼nkÃ¼ normal Ã¶rnekler SOM haritasÄ±ndaki bir BMUâ€™ya yakÄ±n olurken, anomaliler genellikle daha uzak konumlanÄ±r.
# Bu yÃ¼zden en uzak %5â€™lik dilim anomali olarak tanÄ±mlanÄ±r.
esik_uzaklik = np.percentile(bmu_uzakliklari, 95)

# EÅŸik deÄŸeriyle karÅŸÄ±laÅŸtÄ±rma.
# UzaklÄ±ÄŸÄ± eÅŸik deÄŸerinden bÃ¼yÃ¼k olan her Ã¶rnek anomali (1), deÄŸilse normal (0) olarak etiketlenecek.
som_tahminleri = (bmu_uzakliklari >= esik_uzaklik).astype(int)

# SÄ±nÄ±flandÄ±rma baÅŸarÄ± metriklerini yazdÄ±rÄ±lacak.
# precision, recall, f1-score ve destek (support) gibi metrikler gÃ¶sterilir
# zero_division=0: EÄŸer bir sÄ±nÄ±f iÃ§in tahmin yoksa hata yerine sÄ±fÄ±rla doldurulacak.
print("\nğŸ”¹ SOFM-DIST SonuÃ§larÄ±")
print(classification_report(
    gercek_etiketler,
    som_tahminleri,
    target_names=["Normal", "Anomali"],
    zero_division=0
))

